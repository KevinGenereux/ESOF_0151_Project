{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "david-fraud-detection.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9Tpm1Ru5nP8",
        "outputId": "20bbf70d-ae83-42ec-f216-c4f61ed77667",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "piJFKIoM5jfX"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import collections\n",
        "from time import time\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "from sklearn import preprocessing\n",
        "from sklearn import metrics\n",
        "\n",
        "# Models\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore', category=FutureWarning)\n",
        "warnings.filterwarnings('ignore', category=DeprecationWarning)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQHlnTvr5jfc"
      },
      "source": [
        "# read and combine train data by the TransactionID\n",
        "train_identity = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/fraud-detection-data/train_identity.csv\")\n",
        "train_transaction = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/fraud-detection-data/train_transaction.csv\")\n",
        "traindata = pd.merge(train_transaction,train_identity, on='TransactionID', how='left',left_index=True,right_index=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFoUe-Ed5jfg"
      },
      "source": [
        "def prepare_inputs_and_outputs(data):\n",
        "    \n",
        "    # Prepare & save the inputs and outputs features\n",
        "    features = data.drop(['isFraud','TransactionID'], axis = 1)\n",
        "    labels = data[['isFraud']]\n",
        "    \n",
        "    return features, labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGBJ2vBk5jfj"
      },
      "source": [
        "def get_missing_data_percentage(data):\n",
        "    \n",
        "    # where mvp = missing value percentages\n",
        "    mvp = data.isnull().sum() * 100 / len(data)\n",
        "    mvp = pd.DataFrame({'Feature': data.columns,'Percentage': mvp})\n",
        "    \n",
        "    return mvp.sort_values(by ='Percentage', ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCxN6o7n5jfn"
      },
      "source": [
        "def drop_high_missing_data_columns(mvd, data, threshold):\n",
        "    # Where \"mvd\" = missing value data\n",
        "    # Get names of indexes for which column missing data is over 50%\n",
        "    high_missing_data_cols = mvd[mvd['Percentage'] > threshold].index\n",
        "\n",
        "    for col_name in range(len(high_missing_data_cols)):\n",
        "        del data[high_missing_data_cols[col_name]] # Delete rows from dataFrame??? or columns\n",
        "    \n",
        "    return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQoerlZK5jfr"
      },
      "source": [
        "def drop_one_value_columns(data):\n",
        "    \n",
        "    # Drop columns with only 1 unique value.\n",
        "    for column in data.columns:\n",
        "        if len(data[column].unique()) == 1:\n",
        "            #print(traindata[column].name)\n",
        "            data.drop(column,inplace=True,axis=1)\n",
        "            \n",
        "    return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WPIc725i5jfx"
      },
      "source": [
        "def getCategoricalFeatures(data):\n",
        "    columns = list(data)\n",
        "    result = []\n",
        "    for c in columns: \n",
        "        if data.dtypes[c] == np.object:\n",
        "            result.append(c) \n",
        "    return data[result]\n",
        "\n",
        "def getNumericalFeatures(data):\n",
        "    columns = list(data)\n",
        "    result = []\n",
        "    for c in columns: \n",
        "        if data.dtypes[c] != np.object:\n",
        "            result.append(c) \n",
        "    return data[result]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3hxDcdW5jf0"
      },
      "source": [
        "def drop_high_correlation_features(data, threshold):\n",
        "\n",
        "    corr_matrix = data.corr()\n",
        "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
        "    to_drop = [column for column in upper.columns if any(abs(upper[column]) > threshold)]\n",
        "    data = data.drop(columns = to_drop)\n",
        "    \n",
        "    return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSE1yVrx5jf4"
      },
      "source": [
        "def label_encode_categorical_features(data):\n",
        "        \n",
        "    encoder_dict = collections.defaultdict(LabelEncoder)\n",
        "    data = data.apply(lambda x: encoder_dict[x.name].fit_transform(x))\n",
        "    \n",
        "    return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cE1lS-qa5jf8"
      },
      "source": [
        "def split_data(features, labels):\n",
        "    \n",
        "    # Data Splitting: 60% for training, 20% for validation and 20% for testing.\n",
        "    X_train, X_test, Y_train, y_test = train_test_split(features, labels, test_size=0.4)\n",
        "    X_validation, X_test, Y_validation, y_test = train_test_split(X_test, y_test, test_size=0.5)\n",
        "    \n",
        "    return X_train, Y_train, X_test, y_test, X_validation, Y_validation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDfUoKCN5jf_"
      },
      "source": [
        "def selectkbestfeatures(X_train, Y_train, X_validation, X_test, numberOfFeatures):\n",
        "\n",
        "    fit = SelectKBest(score_func=f_classif, k=numberOfFeatures).fit(X_train, Y_train)\n",
        "\n",
        "    X_train = fit.transform(X_train)\n",
        "    X_validation = fit.transform(X_validation)\n",
        "    X_test = fit.transform(X_test)\n",
        "\n",
        "    # Get column names from the best features\n",
        "    X_train_cols = fit.get_support(indices=True)\n",
        "    X_validation_cols = fit.get_support(indices=True)\n",
        "    X_test_cols = fit.get_support(indices=True)\n",
        "\n",
        "    X_train = pd.DataFrame(X_train, columns=X_train_cols)\n",
        "    X_validation = pd.DataFrame(X_validation, columns=X_validation_cols)\n",
        "    X_test = pd.DataFrame(X_test, columns=X_test_cols)\n",
        "\n",
        "    # Create new dataframes with the column names\n",
        "    #X_train = X_train.iloc[:,X_train_cols]\n",
        "    #X_validation = X_validation.iloc[:,X_validation_cols]\n",
        "    #X_test = X_test.iloc[:,X_test_cols]\n",
        "\n",
        "    return X_train, X_validation, X_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4DXZ6J2a5jgB"
      },
      "source": [
        "def evaluate_model(name, model, features, labels):\n",
        "    \n",
        "    start = time()\n",
        "    pred = model.predict(features)\n",
        "    end = time()\n",
        "    \n",
        "    # Print the confusion matrix\n",
        "    print(metrics.confusion_matrix(labels, pred))\n",
        "\n",
        "    # Print the precision and recall, among other metrics\n",
        "    print(metrics.classification_report(labels, pred, digits=3))\n",
        "    \n",
        "    print(name+\" Accuracy - \"+str(round(accuracy_score(labels, pred), 3) * 100)+\"%\")\n",
        "    print(name+\" Precision - \"+str(round(precision_score(labels, pred, average='micro'), 3) * 100)+\"%\")\n",
        "    print(name+\" Recall - \"+str(round(recall_score(labels, pred, average='micro'), 3) * 100)+\"%\")\n",
        "    print(name+\" F1 Score - \"+str(round(f1_score(labels, pred, average='micro'), 3) * 100)+\"%\")\n",
        "    print(name+\" Latency - \"+str(round((end - start) * 1000, 1))+\"ms \\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZxwvqD1k7R1Q"
      },
      "source": [
        "# Separate Features & Labels\n",
        "train_features, train_labels = prepare_inputs_and_outputs(traindata)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANvotlOt7di1"
      },
      "source": [
        "# [PREPROCESSING STAGE 1] - DATA CLEANING\n",
        "\n",
        "# Examine the percentage of missing data for all feature in the training data\n",
        "allFeaturesMissingData = get_missing_data_percentage(train_features)\n",
        "\n",
        "# Drop features with a missing data percentage above the specified threshold\n",
        "train_features = drop_high_missing_data_columns(allFeaturesMissingData, train_features, 70)\n",
        "\n",
        "# Drop features with only 1 distinct value, extremely high or extremely low correlation\n",
        "train_features = drop_one_value_columns(train_features)\n",
        "train_features = drop_high_correlation_features(train_features, 0.80)\n",
        "\n",
        "# Extract the numerical & categorical features from training features\n",
        "numericalFeatures = getNumericalFeatures(train_features)\n",
        "categoricalFeatures = getCategoricalFeatures(train_features)\n",
        "\n",
        "# Get the percentage of missing data for both numerical & categorical features\n",
        "numericalFeaturesMissingData = get_missing_data_percentage(numericalFeatures)\n",
        "categoricalFeaturesMissingData = get_missing_data_percentage(categoricalFeatures)\n",
        "\n",
        "# Impute categorical missing values with \"X\" and numerical missing values with column mean\n",
        "numericalFeatures = numericalFeatures.fillna(numericalFeatures.mean(), inplace=False)\n",
        "categoricalFeatures = categoricalFeatures.fillna(\"X\")\n",
        "\n",
        "# Update missing data and ensure none exists\n",
        "numericalFeaturesMissingData = get_missing_data_percentage(numericalFeatures)\n",
        "categoricalFeaturesMissingData = get_missing_data_percentage(categoricalFeatures)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mt26CGFi5jgE"
      },
      "source": [
        "# [PREPROCESSING STAGE 2] - DATA TRANSFORMATION \n",
        "\n",
        "# Numerically represent the categorical features using label encoding\n",
        "categoricalFeatures = label_encode_categorical_features(categoricalFeatures)\n",
        "\n",
        "# Update training features by replacing the initial data with the imputed data\n",
        "train_features = pd.concat([numericalFeatures, categoricalFeatures], axis=1)\n",
        "\n",
        "# Further split the training data into a train and test sets\n",
        "X_train, Y_train, X_test, Y_test, X_validation, Y_validation = split_data(train_features, train_labels)\n",
        "\n",
        "# Feature Selection using SelectKBest\n",
        "X_train, X_validation, X_test = selectkbestfeatures(X_train, Y_train, X_validation, X_test, 50)\n",
        "\n",
        "# Feature Scaling using Standardization\n",
        "scaler = MinMaxScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_validation = scaler.transform(X_validation)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RX_IuzR8Gjz6"
      },
      "source": [
        "# [PREPROCESSING STAGE 3] - DATA REDUCTION (USING PCA or LDA) (focus here next)\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca = PCA(n_components=25).fit(X_train)\n",
        "\n",
        "X_train_pca = pca.transform(X_train)\n",
        "X_validation_pca = pca.transform(X_validation)\n",
        "X_test_pca = pca.transform(X_test)\n",
        "\n",
        "X_train = pd.DataFrame(data = X_train_pca)\n",
        "X_validation = pd.DataFrame(data = X_validation_pca)\n",
        "X_test = pd.DataFrame(data = X_test_pca)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JEOlx41DGf_c"
      },
      "source": [
        "# [MODEL BUILDING]\n",
        "\n",
        "algorithm = GradientBoostingClassifier()\n",
        "parameters = {\n",
        "    'n_estimators': [5, 50, 250, 500],\n",
        "    'max_depth': [1, 3, 5, 7, 9],\n",
        "    'learning_rate': [0.01, 0.1, 1, 10, 100]\n",
        "}\n",
        "cv = GridSearchCV(algorithm, parameters, cv=5)\n",
        "cv.fit(X_train, Y_train.values.ravel())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugeIK2neHxgy"
      },
      "source": [
        "# [MODEL EVALUATION]\n",
        " \n",
        "evaluate_model('Train Set', cv, X_train, Y_train)\n",
        "evaluate_model('Validation Set', cv, X_validation, Y_validation)\n",
        "evaluate_model('Test Set', cv, X_test, Y_test)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}